{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Data Analysis Assignment\n",
    "By Simona Vasiliauskaite G00263352"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Anscombe's Quartet Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    " 1. Explain the background to the dataset.\n",
    " 2. Calculate the descriptive statistics of the variables in the dataset.\n",
    " 3. Plot the interesting aspects of the dataset.\n",
    " 4. Explain why the dataset is interesting, referring to the plots and statistics above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "\n",
    "Anscombe’s quartet is the name for a famous data set created by Frank Anscombe in 1973 to illustrate the importance of plotting data. Mr. Anscombe was a pioneer in the application of computers to the statistical analysis of data. A classic paper showed that one equation could fit four very different data sets, illustrating the importance of graphing data before analyzing it and the effect of outliers on statistical properties. This particular data set shows that for x-y measurement data, the marginal distributions and Pearson correlation are not sufficient to describe the association between x and y, and that scatterplots are needed as well.\n",
    "\n",
    "Anscombe published 50 research articles and one book, “Computing in Statistical Science through APL” (1981) [Source](https://news.yale.edu/2001/10/23/memoriam-professor-francis-john-anscombe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d12a2c32b623>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Check first 5 rows of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head() # Check first 5 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() # Check last 5 rows of data and total number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Pull up descriptive stats of the data set including mean, standard deiation and count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running some summary statistics I can see that that the x values for all four datasets have a mean equal to 9.0, a median of 6.5, standard deviation of 3.316 with all but one having a minimum value of 4 and maximum value of 14. The y values have similar summary statistics as well but not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s): # Highlight the maximum in a series yellow\n",
    "\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "df.style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas package\n",
    "# Import matplotlib.pyplot\n",
    "# Import seasborn\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Anscombe's data set from my GitHub file\n",
    "\n",
    "df = pd.read_csv(\"https://goo.gl/uKtZqx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df # Print the items of this data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data from table above, each set appears relatively similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Plotting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following figures below show a scatterplot of each dataset along with their linear regression lines. Seaborn already has anscombe dataset saved [Source](https://seaborn.pydata.org/tutorial/regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anscombe = sns.load_dataset(\"anscombe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'I'\"),\n",
    "           ci=None, scatter_kws={\"s\": 80});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'II'\"),\n",
    "           ci=None, scatter_kws={\"s\": 80});\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'III'\"),\n",
    "           ci=None, scatter_kws={\"s\": 80});\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'IV'\"),\n",
    "           ci=None, scatter_kws={\"s\": 80});\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data from table above, each set appears relatively similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that summary measures alone cannot adequately characterize a univariate or bivariate data distribution.\n",
    "Summary statistics allow us to describe a vast, complex dataset using just a few key numbers. This gives us something easy to optimize against.\n",
    "\n",
    "But there’s a danger in relying only on summary statistics and ignoring the overall distribution. Calculating summary statistics, while useful, should only be one piece of data analysis pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
